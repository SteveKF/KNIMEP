%% analyse.tex
\chapter{Forschungsstand}
\label{ch:Forschungsstand}
%% ==============================
Der Startpunkt der repräsentativen Skylines war die Einführung des Skyline Operators \cite{borzsony2001skyline}. Dieser Skyline Operator verhilft es dem User mithilfe eines SQL Queries die Skyline zu berechnen. In dem gleichen Paper wurde auch der Block Nested Loop Algorithmus vorgestellt, auf den später in dieser Arbeit noch eingegangen wird. Zusätzlich wird noch der Divide and Conquer Algorithmus aufgezeigt, der für den worst case\footnote{Jeder Datensatz muss mit jedem anderen verglichen werden.} am schnellsten ist \cite[p. 435]{borzsony2001skyline}. Im Laufe der Jahre wurden weitere Algorithmen vorgestellt, um eine Skyline zu berechnen. Es wurden Ansätze entwickelt, die B/R-Bäume benutzen, um damit die Effizienz zu steigern. Einer dieser Ansätze ist im Paper \cite{Papadias:2003:OPA:872757.872814} zu finden, der durch Branch and Bound nur auf die Knoten des R-Baumes zugreift, die vermutlich Skylinedatensätze enthalten. 
Jedoch reichen bei zu vielen Datensätzen und bei Betrachtung zu vieler Dimensionen Skylines oft nicht mehr aus, da zu viele Datensätze undominiert bleiben und somit keine sinnvolle Entscheidung mit der Skyline getroffen werden kann. Falls der User zum Beispiel nach einem Auto sucht und 100 undominierte Autos ausgegeben werden, kann sich der User schlechter für eines der 100 Autos entscheiden.
Aus diesem Grund wurde das Konzept der repräsentativen Skylines eingeführt und dadurch verschiedene Vorgehensweisen zur Verkleinerung von Skylines. 
Eine Vorgehensweise besteht aus der Relaxation der Dominanzrelation, sodass mehr Datensätze dominiert werden. Weitere sind die Maximierung der Diversität und Signifikanz und die Berücksichtigung von User Feedback. Die Diversität zwischen zwei Datensätzen drückt aus wie verschieden zwei Datensätze sind und wird meistens durch die Distanz zwischen diesen Datensätzen dargestellt. Wohingegen ein Datensatz signifikant ist, wenn dieser jeden vom User angegebenen Threshold erfüllt. Zusätzlich gibt es noch progressive Algorithmen, die während der Berechnung nach und nach alle Skylinedatensätze ausgeben und bei \textit{k} gefunden gestoppt werden können.
%% ==============================
\section{Progressive und sortierungs-basierende Skylines}
\label{ch:Forschungsstand:sec:progSortSky}
%% ==============================
Progressive Algorithmen basieren darauf undominierte Datensätze nach jeder Iteration auszugeben. Dies bietet die Möglichkeit dem Kunden schon nach der ersten Iteration Ergebnisse vorzuzeigen. Jedoch ist das Ziel dieser Algorithmen nur die Skyline zu bestimmen und keine \textit{k} repräsentativen Datensätze zu finden.
Auch wenn progressive Algorithmen nicht direkt repräsentative Skylinedatensätze ausgeben, sind die ausgegebenen Datensätze meistens repräsentativ, da progressive Algorithmen wie \cite{Tan:2001:EPS:645927.672217}, \cite{papadias2005progressive}, \cite{Kossmann:2002:SSS:1287369.1287394} und \cite{Papadias:2003:OPA:872757.872814} keine Dimensionen bevorzugen. Das erzwingt, dass nicht die \textit{k} Datensätze mit den höchsten Werten auf nur einer speziellen Dimension für die repräsentative Skyline ausgesucht werden. Daher kann bei \textit{k} Datensätzen gestoppt werden und erhält damit eine repräsentative Skyline mit einer annehmbaren Repräsentationsgüte.

Algorithmen, die Datensätze zuerst sortieren und daraufhin die Skyline berechnen, können auch genutzt werden, um eine repräsentative Skyline zu bestimmen. Das Problem an diesen Ansätzen (\cite{1260846} und \cite{lee2010z}) ist meistens wie bei den progressiven, dass diese eher für die Berechnung von Skylines benutzt werden und es passieren kann, dass die Repräsentationsgüte der \textit{k} zuerst gefundenen Datensätzen nicht ausreichend genug ist.
%% ==============================
\section{Relaxation der Dominanzrelation}
\label{ch:Forschungsstand:sec:relaxDomRel}
%% ==============================
Die Relaxation der Dominanzrelation ist eine Vorgehensweise, die versucht mit Hilfe der Lösung eines einfacheren Problems sich der Lösung des originalen Problems zu nähern. 
Einer der entwickelten Ansätze besteht darin alle Dimensionen einiger bestimmter Datensätze mit einem $\epsilon$ Faktor zu multiplizieren. Dadurch dominieren diese Datensätze mehr andere Datensätze, die dann für folgende Iterationen oder Vergleiche nicht mehr betrachtet werden. Dieser Ansatz wurde in mehreren Papern (\cite{Koltun05approximatelydominating}, \cite{Su:2007:AMA:1418332.1418454}, \cite{Vassilvitskii:2005:ECS:1132633.1132648} und \cite{Xia:2008:SFD:1546682.1547149}) vorgestellt. Jedoch muss auch dieser Ansatz wie bei den vorher genannten angepasst werden, um genau \textit{k} Datensätze zu erhalten.

Ein weiterer Ansatz ist die \textit{k}-Dominanz, welcher in \cite{Chan:2006:FKS:1142473.1142530}, \cite{Chan:2006:HDS:2117976.2118017} und \cite{5480364} besprochen wird. Hierfür wird der Parameter \textit{k} nicht benutzt, um die Anzahl der repräsentativen Skylinedatensätze festzulegen, sondern wie viele Dimensionen dominiert werden müssen, sodass Dominanz vorliegt. Dies bedeutet, dass ein Datensatz einen anderen dominiert, falls er  in \textit{k} Dimensionen mindestens gleich gut ist und in einer der \textit{k} Dimensionen besser ist. Dies führt bei einem kleinen \textit{k} dazu, dass mehr Datensätze dominiert werden und dadurch wird die Skyline kleiner. Jedoch kann es dazu kommen, dass bei zu kleinen \textit{k} die \textit{k}-dominante Skyline leer ist und bei zu großen die Skyline zu viele Ergebnisse liefert. Mit diesen Extremen kann keine Entscheidungen getroffen werden und aus diesem Grund muss zuerst ein passendes \textit{k} gefunden werden.
%% ==============================
\section{Maximierung der Diversität}
\label{ch:Forschungsstand:sec:maxDiv}
%% ==============================
Viele Algorithmen versuchen die Diversität zu maximieren und ignorieren dabei die Signifikanz von einzelnen Datensätzen. Damit soll erreicht werden, dass nur diverse Datensätze in der Ergebnismenge auftauchen und diese einen guten Überblick über die eigentliche Skyline liefern.
Dies hat zur Folge, dass die Repräsentative, der für die repräsentative Skyline ausgewählten Datensätze, maximiert wird. Allerdings werden dafür Präferenzen des Users bezüglich der Werte einzelner Dimensionen ausgeschlossen. Algorithmen dieses Ansatzes basieren hauptsächlich auf Distanz oder auf Eigenschaften der Skyline und benötigen deswegen als Input eine Skyline. 

Das Ziel des Ansatzes in \cite{Tao:2009:DRS:1546683.1547325} ist es die Distanz zwischen einem nicht-repräsentativen Skyline Datensatz und dessen nächsten repräsentativen zu minimieren. 

Eine weitere Lösung des Problems besteht darin, dass \textit{k} Skylinedatensätze gefunden werden sollen, die die Anzahl von dominierten Datensätzen maximieren \cite{4221657}. Das Problem hierbei besteht, dass bei Daten mit einer hohen Dicht meistens \textit{alle} Ausreißer nicht zur repräsentativen Skyline gehören und dadurch die Repräsentationsgüte reduziert wird.

Der letzte vorgestellte Ansatz für diesen Abschnitt ist die Berechnung einer Distanz basierenden Skyline mit Hilfe der Extreme Learning Machine. Die Extreme Learning Machine ist ein Algorithmus für neuronale Netze \cite{huang2006extreme}, welcher versucht die Skyline in \textit{k} Cluster zu unterteilen. Der nächste Schritt besteht darin einen repräsentativen Datensatz für jedes Cluster auszuwählen. Hierfür wird für jede Datensatzkombination in einem Cluster die Distanz zwischen diesen berechnet. Schlussendlich wird der Datensatz ausgewählt, der in Summe die geringste Distanz zu allen anderen Datensätzen im selben Cluster hat. Dieser Ansatz kann detaillierter in \ref{bai2016distance} nachgelesen werden.
%% ==============================
\section{Weitere Ansätze}
\label{ch:Forschungsstand:sec:userModel}
%% ==============================
Den Anfang für Methoden basierend auf Usermodellierung machte \cite{948}, indem User nach Feedback gefragt wurden, umso die Skyline besser bestimmen zu können.
In \cite{Lofi10efficientcomputation} wurden User direkt aufgefordert ihre präferierten Datensätze auszuwählen und in \cite{lee2008optimal}, \cite{Mindolin:2009:DRI:1687627.1687697}, \cite{Mindolin:2011:PEP:1969331.1969354} und \cite{Zhao10callto} wurde versucht Präferenzen mit Userfeedback herauszufinden.

Algorithmen, die Diversität berücksichtigen, wurden schon vorgestellt. Jedoch gibt es auch Algorithmen, die sowohl auf Diversität als auch auf Signifikanz basieren \cite{magnani2014taking}. Die Diversität zwischen zwei Datensätzen wird dadurch berechnet wie viele Datensätze zwischen diesen liegen. Wohingegen ein Datensatz signifikant ist, wenn dieser für eine bestimmte Dimension einen vom User bestimmten Threshold überschreitet (untere Grenze) oder unterschreitet (obere Grenze).
Signifikanz und Diversität werden mit einem Faktor $\lambda$ gewichtet und danach werden die Datensätze gesucht, die beide Werte maximieren. Genaueres wird in Kapitel \ref{ch:Analyse:sec:repSkyAlgos:subsec:eGreedy} erläutert.
%% ==============================
\section{Preference SQL}
\label{ch:Forschungsstand:sec:prefSQL}
%% ==============================
Damit der User seine eigenen Präferenzen in Standard-SQL ausdrücken kann, muss er diese mit bestimmten Subqueries oder WHERE Klauseln berücksichtigen, was zu einer schlechten Performance führt (vgl. Kapitel 3.1 von \cite{borzsony2001skyline}). Zusätzlich liefern Standard SQL-Queries oft zu viele oder gar keine Ergebnisse, was oft zur Frustration beim Benutzer führt. Um diese Probleme zu verhindern, wurde Preference SQL entwickelt (\cite{kiessling2002foundations} und \cite{kiessling2011preference}).

Hierfür wurden mehrere Präferenzen eingeführt wie zum Beispiel die BETWEEN Präferenz. Mit dieser Präferenz kann der Benutzer angeben, dass eine bestimmte Dimension, wie die Anzahl an PS eines Autos, in einem bestimmten Intervall liegen soll. Daraufhin werden alle Datensätze, dessen Werte für diese Dimension in dem Intervall liegen, präferiert. \cite{kiessling2002preference} zeigt dahingegen eine Implementierung und Erfahrungen von Preference SQL auf. 
Preference SQL wird im Kapitel \ref{ch:Grundlagen:sec:präferenzen} genauer betrachtet, da das Sprachverständnis für die spätere Implementierung benötigt wird.
%% ==============================
%%% End: 